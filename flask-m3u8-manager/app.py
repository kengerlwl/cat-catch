#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Flask M3U8 ä¸‹è½½ç®¡ç†å™¨
æä¾›M3U8è§†é¢‘ä¸‹è½½ã€ä»»åŠ¡ç®¡ç†ã€è½¬æ¢ç­‰åŠŸèƒ½
"""

import os
import json
import uuid
import threading
import subprocess
import time
from datetime import datetime, timedelta
from urllib.parse import urlparse
from pathlib import Path

from flask import Flask, render_template, request, jsonify, send_file, abort, redirect, url_for
from werkzeug.utils import secure_filename
from flask_cors import CORS
import requests
import m3u8

# å¯¼å…¥é…ç½®å’Œæ•°æ®åº“æ¨¡å‹
from config import Config as app_config
from models import db, DownloadRecord, DownloadStatistics, Config, Prompts, LLMConfig
from m3u8_processor import M3U8Processor
from llm_service import init_llm_service_from_db, get_llm_service

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# åŠ è½½é…ç½®
app.config.from_object(app_config)

# åˆå§‹åŒ–æ•°æ®åº“
db.init_app(app)

# é…ç½®
DOWNLOAD_DIR = app_config.DOWNLOAD_DIR
SEGMENTS_DIR = app_config.SEGMENTS_DIR
CONVERTED_DIR = app_config.CONVERTED_DIR

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(DOWNLOAD_DIR, exist_ok=True)
os.makedirs(SEGMENTS_DIR, exist_ok=True)
os.makedirs(CONVERTED_DIR, exist_ok=True)

# å…¨å±€å˜é‡
task_lock = threading.Lock()
settings_lock = threading.Lock()

# è¿è¡Œæ—¶è®¾ç½®ï¼ˆä»æ•°æ®åº“åŠ è½½ï¼Œå¯é€šè¿‡APIä¿®æ”¹ï¼‰
runtime_settings = {}

# ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
task_queue = []
active_tasks = {}  # å­˜å‚¨æ´»è·ƒçš„ä»»åŠ¡çº¿ç¨‹å’Œåœæ­¢äº‹ä»¶
max_concurrent_tasks = 2  # é»˜è®¤å€¼ï¼Œå°†åœ¨load_runtime_settingsä¸­æ›´æ–°

def check_database_ready():
    """æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å‡†å¤‡å°±ç»ª"""
    try:
        # ç®€å•æ£€æŸ¥ï¼šæ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ä¸ºç©º
        db_path = app.config['SQLALCHEMY_DATABASE_URI'].replace('sqlite:///', '')
        if not os.path.exists(db_path) or os.path.getsize(db_path) == 0:
            return False

        # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨
        with app.app_context():
            from sqlalchemy import inspect
            inspector = inspect(db.engine)
            tables = inspector.get_table_names()
            required_tables = ['download_records', 'config', 'prompts', 'download_statistics']

            for table in required_tables:
                if table not in tables:
                    print(f"ç¼ºå°‘è¡¨: {table}")
                    return False

            return True
    except Exception as e:
        print(f"æ•°æ®åº“å°±ç»ªæ£€æŸ¥å¤±è´¥: {e}")
        return False

# ä»»åŠ¡çº¿ç¨‹ç®¡ç†
class TaskThread:
    """ä»»åŠ¡çº¿ç¨‹ç®¡ç†ç±»"""
    def __init__(self, task_id):
        self.task_id = task_id
        self.thread = None
        self.stop_event = threading.Event()

    def start(self, target):
        """å¯åŠ¨çº¿ç¨‹"""
        self.thread = threading.Thread(target=target, args=(self,))
        self.thread.start()

    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self.stop_event.set()

    def is_stopped(self):
        """æ£€æŸ¥æ˜¯å¦å·²åœæ­¢"""
        return self.stop_event.is_set()


def get_ai_optimized_title(original_title):
    """
    ä½¿ç”¨AIä¼˜åŒ–ç”µå½±æ ‡é¢˜

    Args:
        original_title: åŸå§‹æ ‡é¢˜

    Returns:
        ä¼˜åŒ–åçš„æ ‡é¢˜ï¼Œå¦‚æœAIå¤„ç†å¤±è´¥åˆ™è¿”å›åŸå§‹æ ‡é¢˜
    """
    try:
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIå‘½ååŠŸèƒ½
        enable_ai_naming = Config.get_value('enable_ai_naming', False)
        if not enable_ai_naming:
            return original_title

        # è·å–LLMæœåŠ¡
        llm_service = get_llm_service()
        if not llm_service:
            print("LLMæœåŠ¡æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸå§‹æ ‡é¢˜")
            return original_title

        # æ£€æŸ¥movie_name_extractor promptæ˜¯å¦å­˜åœ¨
        prompt_value = Prompts.get_prompt('movie_name_extractor')
        if not prompt_value:
            print("movie_name_extractor promptä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹æ ‡é¢˜")
            return original_title

        # ä½¿ç”¨AIæå–ç”µå½±åç§°
        print(f"æ­£åœ¨ä½¿ç”¨AIä¼˜åŒ–æ ‡é¢˜: {original_title}")

        response = llm_service.chat_with_prompt(
            user_message=original_title,
            prompt_key='movie_name_extractor',
            temperature=0.3,  # ä½¿ç”¨è¾ƒä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ
            max_tokens=100
        )

        if response.get('success'):
            optimized_title = llm_service.extract_content(response)
            if optimized_title and optimized_title.strip():
                print(f"AIä¼˜åŒ–åçš„æ ‡é¢˜: {optimized_title}")
                return optimized_title.strip()
            else:
                print("AIè¿”å›ç©ºç»“æœï¼Œä½¿ç”¨åŸå§‹æ ‡é¢˜")
                return original_title
        else:
            print(f"AIå¤„ç†å¤±è´¥: {response.get('error', 'æœªçŸ¥é”™è¯¯')}ï¼Œä½¿ç”¨åŸå§‹æ ‡é¢˜")
            return original_title

    except Exception as e:
        print(f"AIæ ‡é¢˜ä¼˜åŒ–å¼‚å¸¸: {str(e)}ï¼Œä½¿ç”¨åŸå§‹æ ‡é¢˜")
        return original_title




def load_runtime_settings():
    """ä»æ•°æ®åº“åŠ è½½è¿è¡Œæ—¶è®¾ç½®"""
    global runtime_settings, max_concurrent_tasks

    try:
        # è·å–æ•°æ®åº“ä¸­çš„æ‰€æœ‰é…ç½®
        db_configs = Config.get_all_configs()

        # åˆå¹¶é»˜è®¤é…ç½®å’Œæ•°æ®åº“é…ç½®
        runtime_settings = app_config.USER_CONFIGURABLE.copy()
        runtime_settings.update(db_configs)

        # æ›´æ–°å…¨å±€å˜é‡
        max_concurrent_tasks = runtime_settings.get('max_concurrent_tasks', app_config.DEFAULT_MAX_CONCURRENT_TASKS)

        print(f"âœ… å·²åŠ è½½é…ç½®: {runtime_settings}")

    except Exception as e:
        print(f"âš ï¸ åŠ è½½é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        runtime_settings = app_config.USER_CONFIGURABLE.copy()
        max_concurrent_tasks = runtime_settings['max_concurrent_tasks']


def save_runtime_setting(key, value, value_type='str', description=''):
    """ä¿å­˜å•ä¸ªè¿è¡Œæ—¶è®¾ç½®åˆ°æ•°æ®åº“"""
    try:
        Config.set_value(key, value, value_type, description)
        runtime_settings[key] = value
        print(f"âœ… å·²ä¿å­˜é…ç½® {key}: {value}")
        return True
    except Exception as e:
        print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥ {key}: {e}")
        return False

def download_segment(url, filepath, headers=None, timeout=None):
    """ä¸‹è½½å•ä¸ªåˆ‡ç‰‡"""
    try:
        timeout = timeout or runtime_settings['download_timeout']
        response = requests.get(url, headers=headers or {}, stream=True, timeout=timeout)
        response.raise_for_status()

        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=app_config.CHUNK_SIZE):
                if chunk:
                    f.write(chunk)
        return True
    except Exception as e:
        print(f"ä¸‹è½½åˆ‡ç‰‡å¤±è´¥ {url}: {e}")
        return False

def process_task_queue():
    """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
    global active_tasks, max_concurrent_tasks

    while len(active_tasks) < max_concurrent_tasks and task_queue:
        task_id = task_queue.pop(0)

        # ä»æ•°æ®åº“è·å–ä»»åŠ¡è®°å½•
        with app.app_context():
            record = DownloadRecord.get_by_task_id(task_id)
            if record and record.status == "queued":
                # åˆ›å»ºä»»åŠ¡çº¿ç¨‹
                task_thread = TaskThread(task_id)
                active_tasks[task_id] = task_thread

                # æ›´æ–°çŠ¶æ€ä¸ºpending
                record.status = "pending"
                db.session.commit()

                # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
                task_thread.start(download_m3u8_task)

def download_m3u8_task(task_thread):
    """ä¸‹è½½M3U8ä»»åŠ¡çš„ä¸»å‡½æ•° - ä½¿ç”¨æ–°çš„M3U8å¤„ç†å™¨"""
    task_id = task_thread.task_id

    with app.app_context():
        try:
            # ä»æ•°æ®åº“è·å–ä»»åŠ¡è®°å½•
            record = DownloadRecord.get_by_task_id(task_id)
            if not record:
                print(f"ä»»åŠ¡è®°å½•ä¸å­˜åœ¨: {task_id}")
                return

            # æ›´æ–°çŠ¶æ€ä¸ºä¸‹è½½ä¸­
            record.mark_downloading()
            db.session.commit()

            # åˆ›å»ºä»»åŠ¡ç›®å½•
            task_dir = os.path.join(SEGMENTS_DIR, record.title)
            os.makedirs(task_dir, exist_ok=True)
            record.segments_path = task_dir
            db.session.commit()

            # ä½¿ç”¨æ–°çš„M3U8å¤„ç†å™¨
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
            processor = M3U8Processor(record.url, headers)

            # è§£æM3U8
            if not processor.parse_m3u8():
                record.mark_failed("M3U8è§£æå¤±è´¥")
                db.session.commit()
                return

            record.total_segments = len(processor.segments)
            db.session.commit()

            # æ£€æŸ¥æ˜¯å¦æœ‰åŠ å¯†åˆ‡ç‰‡
            encrypted_count = sum(1 for seg in processor.segments if seg['encrypted'])
            if encrypted_count > 0:
                print(f"æ£€æµ‹åˆ° {encrypted_count} ä¸ªåŠ å¯†åˆ‡ç‰‡ï¼Œå°†è‡ªåŠ¨è§£å¯†")

            # åˆ›å»ºè¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°
            def update_progress(downloaded, total):
                record.update_progress(downloaded, total)
                db.session.commit()
                print(f"è¿›åº¦æ›´æ–°: {downloaded}/{total} ({record.progress}%)")

            # ä¸‹è½½æ‰€æœ‰åˆ‡ç‰‡ï¼ˆåŒ…å«è§£å¯†å¤„ç†ï¼‰- ä½¿ç”¨é…ç½®çš„çº¿ç¨‹æ•°è¿›è¡Œå¹¶å‘ä¸‹è½½
            success = processor.download_all_segments(
                task_dir,
                max_retries=runtime_settings['max_retry_count'],
                progress_callback=update_progress,
                max_workers=record.thread_count  # ä½¿ç”¨ä»»åŠ¡é…ç½®çš„çº¿ç¨‹æ•°
            )

            if success:
                # åˆ›å»ºæœ¬åœ°M3U8æ–‡ä»¶
                processor.create_local_m3u8(task_dir)

                record.mark_completed()
                record.downloaded_segments = len(processor.segments)
                db.session.commit()
                print(f"ä»»åŠ¡ {task_id} ä¸‹è½½å®Œæˆ")
            else:
                record.mark_failed("éƒ¨åˆ†åˆ‡ç‰‡ä¸‹è½½å¤±è´¥")
                db.session.commit()
                print(f"ä»»åŠ¡ {task_id} ä¸‹è½½å¤±è´¥")

        except Exception as e:
            record = DownloadRecord.get_by_task_id(task_id)
            if record:
                record.mark_failed(str(e))
                db.session.commit()
            print(f"ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
        finally:
            # ä»æ´»è·ƒä»»åŠ¡ä¸­ç§»é™¤
            if task_id in active_tasks:
                del active_tasks[task_id]
            # å¤„ç†é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªä»»åŠ¡
            process_task_queue()

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')


@app.route('/prompts')
def prompts_page():
    """Promptç®¡ç†é¡µé¢"""
    return render_template('prompts.html')


@app.route('/llm-config')
def llm_config_page():
    """LLMé…ç½®é¡µé¢"""
    return render_template('llm_config.html')

@app.route('/api/tasks', methods=['GET'])
def get_tasks():
    """è·å–æ‰€æœ‰ä¸‹è½½ä»»åŠ¡"""
    try:
        if not check_database_ready():
            # æ•°æ®åº“è¡¨è¿˜æœªåˆ›å»ºï¼Œè¿”å›ç©ºåˆ—è¡¨
            return jsonify({'tasks': [], 'database_initializing': True})

        # ä»æ•°æ®åº“è·å–æ‰€æœ‰ä»»åŠ¡
        tasks = DownloadRecord.query.order_by(DownloadRecord.created_at.desc()).all()
        tasks_data = [task.to_dict() for task in tasks]
        return jsonify({'tasks': tasks_data, 'database_initializing': False})
    except Exception as e:
        return jsonify({'error': f'è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks', methods=['POST'])
def create_task():
    """åˆ›å»ºæ–°çš„ä¸‹è½½ä»»åŠ¡"""
    global max_concurrent_tasks

    data = request.json
    url = data.get('url', '').strip()
    title = data.get('title', '').strip()
    custom_dir = data.get('custom_dir', '').strip()
    thread_count = data.get('thread_count', runtime_settings['thread_count'])

    if not url:
        return jsonify({'error': 'è¯·æä¾›M3U8é“¾æ¥'}), 400

    # éªŒè¯çº¿ç¨‹æ•°
    if thread_count < app_config.MIN_THREAD_COUNT or thread_count > app_config.MAX_THREAD_COUNT:
        thread_count = runtime_settings['thread_count']

    # ç”Ÿæˆä»»åŠ¡ID
    task_id = str(uuid.uuid4())

    # å¦‚æœæ²¡æœ‰æä¾›æ ‡é¢˜ï¼Œä»URLç”Ÿæˆ
    if not title:
        parsed_url = urlparse(url)
        title = parsed_url.path.split('/')[-1] or f"m3u8_{int(time.time())}"
        if title.endswith('.m3u8'):
            title = title[:-5]

    # ä½¿ç”¨AIä¼˜åŒ–æ ‡é¢˜ï¼ˆå¦‚æœå¯ç”¨äº†AIå‘½ååŠŸèƒ½ï¼‰
    original_title = title
    title = get_ai_optimized_title(title)

    # å¦‚æœAIä¼˜åŒ–åçš„æ ‡é¢˜ä¸åŸæ ‡é¢˜ä¸åŒï¼Œè®°å½•æ—¥å¿—
    if title != original_title:
        print(f"æ ‡é¢˜å·²é€šè¿‡AIä¼˜åŒ–: '{original_title}' -> '{title}'")

    try:
        # åˆ›å»ºæ•°æ®åº“è®°å½•
        record = DownloadRecord(task_id, url, title, custom_dir, thread_count)

        # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç«‹å³å¼€å§‹ä¸‹è½½
        if len(active_tasks) < max_concurrent_tasks:
            record.status = "pending"
            db.session.add(record)
            db.session.commit()

            # åˆ›å»ºä»»åŠ¡çº¿ç¨‹
            task_thread = TaskThread(task_id)
            active_tasks[task_id] = task_thread

            # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
            task_thread.start(download_m3u8_task)
        else:
            # æ·»åŠ åˆ°é˜Ÿåˆ—
            record.mark_queued()
            db.session.add(record)
            db.session.commit()
            task_queue.append(task_id)

        return jsonify({'task_id': task_id, 'message': 'ä»»åŠ¡åˆ›å»ºæˆåŠŸ'})

    except Exception as e:
        db.session.rollback()
        return jsonify({'error': f'åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks/<task_id>', methods=['GET'])
def get_task(task_id):
    """è·å–å•ä¸ªä»»åŠ¡ä¿¡æ¯"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404
        return jsonify(record.to_dict())
    except Exception as e:
        return jsonify({'error': f'è·å–ä»»åŠ¡å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks/<task_id>/pause', methods=['POST'])
def pause_task(task_id):
    """æš‚åœä»»åŠ¡"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        if record.status == "downloading":
            # åœæ­¢çº¿ç¨‹
            if task_id in active_tasks:
                active_tasks[task_id].stop()

            record.mark_paused()
            db.session.commit()
            return jsonify({'message': 'ä»»åŠ¡å·²æš‚åœ'})
        else:
            return jsonify({'error': 'ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æš‚åœ'}), 400
    except Exception as e:
        return jsonify({'error': f'æš‚åœä»»åŠ¡å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks/<task_id>/resume', methods=['POST'])
def resume_task(task_id):
    """æ¢å¤ä»»åŠ¡"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        if record.status == "paused":
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥ç«‹å³å¼€å§‹ä¸‹è½½
            if len(active_tasks) < max_concurrent_tasks:
                record.status = "pending"
                db.session.commit()

                # åˆ›å»ºæ–°çš„ä»»åŠ¡çº¿ç¨‹
                task_thread = TaskThread(task_id)
                active_tasks[task_id] = task_thread

                # å¯åŠ¨ä¸‹è½½çº¿ç¨‹
                task_thread.start(download_m3u8_task)
            else:
                # æ·»åŠ åˆ°é˜Ÿåˆ—
                record.mark_queued()
                db.session.commit()
                task_queue.append(task_id)

            return jsonify({'message': 'ä»»åŠ¡å·²æ¢å¤'})
        else:
            return jsonify({'error': 'ä»»åŠ¡çŠ¶æ€ä¸å…è®¸æ¢å¤'}), 400
    except Exception as e:
        return jsonify({'error': f'æ¢å¤ä»»åŠ¡å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks/<task_id>/update_url', methods=['POST'])
def update_task_url(task_id):
    """æ›´æ–°ä»»åŠ¡URL"""
    data = request.json
    new_url = data.get('url', '').strip()
    new_title = data.get('title', '').strip()

    if not new_url:
        return jsonify({'error': 'è¯·æä¾›æ–°çš„URL'}), 400

    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        if record.status == "downloading":
            return jsonify({'error': 'è¯·å…ˆæš‚åœä»»åŠ¡å†æ›´æ–°URL'}), 400

        record.url = new_url
        if new_title:
            record.title = new_title
        record.updated_at = datetime.utcnow()
        db.session.commit()

        return jsonify({'message': 'ä»»åŠ¡å·²æ›´æ–°'})
    except Exception as e:
        return jsonify({'error': f'æ›´æ–°ä»»åŠ¡å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks/<task_id>/delete', methods=['DELETE'])
def delete_task(task_id):
    """åˆ é™¤ä»»åŠ¡"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if record:
            # åœæ­¢ä¸‹è½½
            if record.status == "downloading" and task_id in active_tasks:
                active_tasks[task_id].stop()
                del active_tasks[task_id]

            # ä»é˜Ÿåˆ—ä¸­ç§»é™¤
            if task_id in task_queue:
                task_queue.remove(task_id)

            # åˆ é™¤æ•°æ®åº“è®°å½•
            db.session.delete(record)
            db.session.commit()

        return jsonify({'message': 'ä»»åŠ¡å·²åˆ é™¤'})
    except Exception as e:
        return jsonify({'error': f'åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}'}), 500

# è®¾ç½®ç®¡ç†API
@app.route('/api/settings', methods=['GET'])
def get_settings():
    """è·å–å½“å‰è®¾ç½®"""
    with settings_lock:
        current_settings = runtime_settings.copy()
        current_settings.update({
            'max_concurrent_tasks': max_concurrent_tasks,
            'active_tasks_count': len(active_tasks),
            'queued_tasks_count': len(task_queue),
            'min_thread_count': app_config.MIN_THREAD_COUNT,
            'max_thread_count': app_config.MAX_THREAD_COUNT,
            'min_concurrent_tasks': app_config.MIN_CONCURRENT_TASKS,
            'max_concurrent_tasks_limit': app_config.MAX_CONCURRENT_TASKS
        })
    return jsonify(current_settings)

@app.route('/api/settings', methods=['POST'])
def update_settings():
    """æ›´æ–°è®¾ç½®"""
    global max_concurrent_tasks

    data = request.json
    updated = {}

    with settings_lock:
        # æ›´æ–°çº¿ç¨‹æ•°
        if 'thread_count' in data:
            thread_count = int(data['thread_count'])
            if app_config.MIN_THREAD_COUNT <= thread_count <= app_config.MAX_THREAD_COUNT:
                if save_runtime_setting('thread_count', thread_count, 'int', 'é»˜è®¤çº¿ç¨‹æ•°'):
                    updated['thread_count'] = thread_count

        # æ›´æ–°æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
        if 'max_concurrent_tasks' in data:
            concurrent_tasks = int(data['max_concurrent_tasks'])
            if app_config.MIN_CONCURRENT_TASKS <= concurrent_tasks <= app_config.MAX_CONCURRENT_TASKS:
                if save_runtime_setting('max_concurrent_tasks', concurrent_tasks, 'int', 'æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°'):
                    max_concurrent_tasks = concurrent_tasks
                    updated['max_concurrent_tasks'] = concurrent_tasks
                    # å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
                    process_task_queue()

        # æ›´æ–°ä¸‹è½½è¶…æ—¶æ—¶é—´
        if 'download_timeout' in data:
            timeout = int(data['download_timeout'])
            if 5 <= timeout <= 300:  # 5ç§’åˆ°5åˆ†é’Ÿ
                if save_runtime_setting('download_timeout', timeout, 'int', 'ä¸‹è½½è¶…æ—¶æ—¶é—´(ç§’)'):
                    updated['download_timeout'] = timeout

        # æ›´æ–°æœ€å¤§é‡è¯•æ¬¡æ•°
        if 'max_retry_count' in data:
            retry_count = int(data['max_retry_count'])
            if 0 <= retry_count <= 10:
                if save_runtime_setting('max_retry_count', retry_count, 'int', 'æœ€å¤§é‡è¯•æ¬¡æ•°'):
                    updated['max_retry_count'] = retry_count

        # æ›´æ–°FFmpegçº¿ç¨‹æ•°
        if 'ffmpeg_threads' in data:
            ffmpeg_threads = int(data['ffmpeg_threads'])
            if 1 <= ffmpeg_threads <= 16:
                if save_runtime_setting('ffmpeg_threads', ffmpeg_threads, 'int', 'FFmpegè½¬æ¢çº¿ç¨‹æ•°'):
                    updated['ffmpeg_threads'] = ffmpeg_threads

        # æ›´æ–°è‡ªåŠ¨æ¸…ç†å¤©æ•°
        if 'auto_cleanup_days' in data:
            cleanup_days = int(data['auto_cleanup_days'])
            if 1 <= cleanup_days <= 30:
                if save_runtime_setting('auto_cleanup_days', cleanup_days, 'int', 'è‡ªåŠ¨æ¸…ç†å¤©æ•°'):
                    updated['auto_cleanup_days'] = cleanup_days

        # æ›´æ–°AIå‘½ååŠŸèƒ½å¼€å…³
        if 'enable_ai_naming' in data:
            enable_ai_naming = bool(data['enable_ai_naming'])
            if save_runtime_setting('enable_ai_naming', enable_ai_naming, 'bool', 'å¯ç”¨AIæ™ºèƒ½å‘½ååŠŸèƒ½'):
                updated['enable_ai_naming'] = enable_ai_naming

    if updated:
        return jsonify({'message': 'è®¾ç½®æ›´æ–°æˆåŠŸ', 'updated': updated})
    else:
        return jsonify({'error': 'æ²¡æœ‰æœ‰æ•ˆçš„è®¾ç½®æ›´æ–°'}), 400

@app.route('/api/settings/reset', methods=['POST'])
def reset_settings():
    """é‡ç½®è®¾ç½®ä¸ºé»˜è®¤å€¼"""
    global max_concurrent_tasks

    with settings_lock:
        try:
            # é‡ç½®æ‰€æœ‰é…ç½®åˆ°é»˜è®¤å€¼
            default_configs = app_config.USER_CONFIGURABLE
            for key, value in default_configs.items():
                # ç¡®å®šå€¼ç±»å‹
                value_type = 'int' if isinstance(value, int) else 'float' if isinstance(value, float) else 'bool' if isinstance(value, bool) else 'str'
                save_runtime_setting(key, value, value_type)

            # æ›´æ–°å…¨å±€å˜é‡
            max_concurrent_tasks = runtime_settings['max_concurrent_tasks']

            return jsonify({'message': 'è®¾ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼'})
        except Exception as e:
            return jsonify({'error': f'é‡ç½®è®¾ç½®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/settings/all', methods=['GET'])
def get_all_settings():
    """è·å–æ‰€æœ‰é…ç½®é¡¹ï¼ˆåŒ…æ‹¬æ•°æ®åº“ä¸­çš„é…ç½®ï¼‰"""
    try:
        if not check_database_ready():
            # æ•°æ®åº“è¡¨è¿˜æœªåˆ›å»ºï¼Œè¿”å›é»˜è®¤é…ç½®
            return jsonify({
                'configs': [],
                'runtime_settings': runtime_settings,
                'total_count': 0,
                'database_initializing': True
            })

        with app.app_context():
            configs = Config.query.all()
            config_list = [config.to_dict() for config in configs]

            return jsonify({
                'configs': config_list,
                'runtime_settings': runtime_settings,
                'total_count': len(config_list),
                'database_initializing': False
            })
    except Exception as e:
        return jsonify({'error': f'è·å–é…ç½®å¤±è´¥: {str(e)}'}), 500

@app.route('/api/queue/status', methods=['GET'])
def get_queue_status():
    """è·å–é˜Ÿåˆ—çŠ¶æ€"""
    try:
        if not check_database_ready():
            # æ•°æ®åº“è¡¨è¿˜æœªåˆ›å»ºï¼Œè¿”å›é»˜è®¤çŠ¶æ€
            return jsonify({
                'active_tasks': 0,
                'queued_tasks': 0,
                'max_concurrent_tasks': max_concurrent_tasks,
                'total_tasks': 0,
                'active_task_ids': [],
                'queued_task_ids': [],
                'database_initializing': True
            })

        total_tasks = DownloadRecord.query.count()
        return jsonify({
            'active_tasks': len(active_tasks),
            'queued_tasks': len(task_queue),
            'max_concurrent_tasks': max_concurrent_tasks,
            'total_tasks': total_tasks,
            'active_task_ids': list(active_tasks.keys()),
            'queued_task_ids': task_queue,
            'database_initializing': False
        })
    except Exception as e:
        return jsonify({'error': f'è·å–é˜Ÿåˆ—çŠ¶æ€å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks/<task_id>/convert', methods=['POST'])
def convert_to_mp4(task_id):
    """å°†å®Œæˆçš„M3U8ä»»åŠ¡è½¬æ¢ä¸ºMP4"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        if record.status != "completed":
            return jsonify({'error': 'åªèƒ½è½¬æ¢å·²å®Œæˆçš„ä»»åŠ¡'}), 400

        if not record.segments_path or not os.path.exists(record.segments_path):
            return jsonify({'error': 'åˆ‡ç‰‡æ–‡ä»¶ä¸å­˜åœ¨'}), 400

        # åˆ›å»ºè½¬æ¢è¾“å‡ºç›®å½•
        output_path = os.path.join(CONVERTED_DIR, f"{record.title}.mp4")

        # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
        segments_list = []
        for filename in sorted(os.listdir(record.segments_path)):
            if filename.endswith('.ts'):
                segments_list.append(os.path.join(record.segments_path, filename))

        if not segments_list:
            return jsonify({'error': 'æ²¡æœ‰æ‰¾åˆ°åˆ‡ç‰‡æ–‡ä»¶'}), 400

        # ä½¿ç”¨ffmpegåˆå¹¶åˆ‡ç‰‡
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨ï¼Œä½¿ç”¨UTF-8ç¼–ç 
        list_file = os.path.join(record.segments_path, 'filelist.txt')
        with open(list_file, 'w', encoding='utf-8') as f:
            for segment_path in segments_list:
                # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶æ­£ç¡®è½¬ä¹‰
                abs_path = os.path.abspath(segment_path)
                # åœ¨è·¯å¾„ä¸­çš„å•å¼•å·éœ€è¦è½¬ä¹‰
                escaped_path = abs_path.replace("'", "'\"'\"'")
                f.write(f"file '{escaped_path}'\n")

        # æ‰§è¡Œffmpegå‘½ä»¤
        ffmpeg_path = app_config.FFMPEG_PATH
        print(f"ä½¿ç”¨ FFmpeg è·¯å¾„: {ffmpeg_path}")

        cmd = [
            ffmpeg_path, '-f', 'concat', '-safe', '0',
            '-i', list_file, '-c', 'copy', output_path, '-y'
        ]

        print(f"æ‰§è¡Œ FFmpeg å‘½ä»¤: {' '.join(cmd)}")
        print(f"æ–‡ä»¶åˆ—è¡¨è·¯å¾„: {list_file}")
        print(f"è¾“å‡ºè·¯å¾„: {output_path}")

        # æ£€æŸ¥æ–‡ä»¶åˆ—è¡¨å†…å®¹
        try:
            with open(list_file, 'r', encoding='utf-8') as f:
                content = f.read()
                print(f"æ–‡ä»¶åˆ—è¡¨å†…å®¹:\n{content}")
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")

        result = subprocess.run(cmd, capture_output=True, text=True)

        print(f"FFmpeg è¿”å›ç : {result.returncode}")
        if result.stdout:
            print(f"FFmpeg è¾“å‡º: {result.stdout}")
        if result.stderr:
            print(f"FFmpeg é”™è¯¯: {result.stderr}")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(list_file):
            os.remove(list_file)

        if result.returncode == 0:
            # è·å–æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0

            # æ›´æ–°æ•°æ®åº“è®°å½• - æ ‡è®°ä¸ºå·²è½¬æ¢
            record.mark_converted(output_path, file_size)
            db.session.commit()

            return jsonify({'message': 'è½¬æ¢æˆåŠŸ', 'output_path': output_path, 'converted': True})
        else:
            # å¦‚æœ concat æ–¹æ³•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥åˆå¹¶ TS æ–‡ä»¶
            print("concat æ–¹æ³•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")

            try:
                # æ–¹æ³•2ï¼šä½¿ç”¨ copy åè®®ç›´æ¥åˆå¹¶
                temp_output = output_path + '.temp'

                # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æ–‡ä»¶åæ˜ å°„
                simple_segments = []
                for i, segment_path in enumerate(segments_list):
                    if os.path.exists(segment_path):
                        simple_segments.append(segment_path)

                if simple_segments:
                    # ä½¿ç”¨ binary æ¨¡å¼ç›´æ¥åˆå¹¶æ–‡ä»¶
                    with open(temp_output, 'wb') as outfile:
                        for segment_path in simple_segments:
                            try:
                                with open(segment_path, 'rb') as infile:
                                    outfile.write(infile.read())
                            except Exception as e:
                                print(f"è¯»å–åˆ‡ç‰‡æ–‡ä»¶å¤±è´¥ {segment_path}: {e}")
                                continue

                    # ä½¿ç”¨ ffmpeg è½¬æ¢åˆå¹¶åçš„æ–‡ä»¶
                    convert_cmd = [
                        ffmpeg_path, '-i', temp_output,
                        '-c', 'copy', '-bsf:a', 'aac_adtstoasc',
                        output_path, '-y'
                    ]

                    print(f"æ‰§è¡Œå¤‡ç”¨è½¬æ¢å‘½ä»¤: {' '.join(convert_cmd)}")
                    convert_result = subprocess.run(convert_cmd, capture_output=True, text=True)

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_output):
                        os.remove(temp_output)

                    if convert_result.returncode == 0:
                        # è·å–æ–‡ä»¶å¤§å°
                        file_size = os.path.getsize(output_path) if os.path.exists(output_path) else 0

                        # æ›´æ–°æ•°æ®åº“è®°å½• - æ ‡è®°ä¸ºå·²è½¬æ¢
                        record.mark_converted(output_path, file_size)
                        db.session.commit()

                        return jsonify({'message': 'è½¬æ¢æˆåŠŸï¼ˆä½¿ç”¨å¤‡ç”¨æ–¹æ³•ï¼‰', 'output_path': output_path, 'converted': True})
                    else:
                        print(f"å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {convert_result.stderr}")
                        return jsonify({'error': f'è½¬æ¢å¤±è´¥: {result.stderr}\nå¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {convert_result.stderr}'}), 500
                else:
                    return jsonify({'error': 'æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ‡ç‰‡æ–‡ä»¶'}), 400

            except Exception as e:
                print(f"å¤‡ç”¨è½¬æ¢æ–¹æ³•å‡ºé”™: {e}")
                return jsonify({'error': f'è½¬æ¢å¤±è´¥: {result.stderr}\nå¤‡ç”¨æ–¹æ³•å‡ºé”™: {str(e)}'}), 500

    except Exception as e:
        return jsonify({'error': f'è½¬æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}'}), 500

@app.route('/api/tasks/<task_id>/play')
def play_task(task_id):
    """è·³è½¬åˆ°æ’­æ”¾é¡µé¢"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        # è¿”å›æ’­æ”¾é¡µé¢URL
        play_url = f"/play/{task_id}"
        return jsonify({'play_url': play_url})
    except Exception as e:
        return jsonify({'error': f'è·å–æ’­æ”¾é“¾æ¥å¤±è´¥: {str(e)}'}), 500

@app.route('/play/<task_id>')
def play_page(task_id):
    """æ’­æ”¾é¡µé¢"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return "ä»»åŠ¡ä¸å­˜åœ¨", 404

        return render_template('play.html', task=record.to_dict())
    except Exception as e:
        return f"æ’­æ”¾é¡µé¢åŠ è½½å¤±è´¥: {str(e)}", 500

@app.route('/api/download/<task_id>')
def download_file(task_id):
    """ä¸‹è½½è½¬æ¢åçš„æ–‡ä»¶"""
    try:
        record = DownloadRecord.get_by_task_id(task_id)
        if not record:
            return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

        if not record.download_path or not os.path.exists(record.download_path):
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404

        return send_file(record.download_path, as_attachment=True)
    except Exception as e:
        return jsonify({'error': f'ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}'}), 500

# æ•°æ®åº“åˆå§‹åŒ–å’Œåº”ç”¨å¯åŠ¨å‰çš„æ“ä½œ
def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“ - é‡æ„åçš„ç®€åŒ–ç‰ˆæœ¬"""
    with app.app_context():
        db_path = app.config['SQLALCHEMY_DATABASE_URI'].replace('sqlite:///', '')

        # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        is_new_database = not os.path.exists(db_path) or os.path.getsize(db_path) == 0

        if is_new_database:
            print("ğŸ†• æ£€æµ‹åˆ°æ–°ç¯å¢ƒï¼Œæ­£åœ¨åˆ›å»ºæ•°æ®åº“...")
            # å¦‚æœæ˜¯ç©ºæ–‡ä»¶ï¼Œå…ˆåˆ é™¤
            if os.path.exists(db_path):
                os.remove(db_path)
        else:
            print("ğŸ“‚ æ•°æ®åº“æ–‡ä»¶å·²å­˜åœ¨")

        # åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        print("ğŸ“‹ åˆ›å»ºæ•°æ®åº“è¡¨...")
        db.create_all()

        # éªŒè¯è¡¨åˆ›å»º
        from sqlalchemy import inspect
        inspector = inspect(db.engine)
        tables = inspector.get_table_names()
        print(f"âœ… æ•°æ®åº“è¡¨: {tables}")

        # åˆå§‹åŒ–é»˜è®¤æ•°æ®ï¼ˆä»…åœ¨æ–°æ•°æ®åº“æˆ–ç¼ºå°‘é»˜è®¤æ•°æ®æ—¶ï¼‰
        _init_default_data()

        # åŠ è½½è¿è¡Œæ—¶è®¾ç½®
        load_runtime_settings()

        # åˆå§‹åŒ–LLMæœåŠ¡
        try:
            init_llm_service_from_db()
            print("âœ… LLMæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ LLMæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")

        # æ¢å¤æœªå®Œæˆçš„ä»»åŠ¡ï¼ˆä»…ç°æœ‰æ•°æ®åº“ï¼‰
        if not is_new_database:
            try:
                restore_active_tasks()
                print("âœ… ä»»åŠ¡æ¢å¤å®Œæˆ")
            except Exception as e:
                print(f"âŒ ä»»åŠ¡æ¢å¤å¤±è´¥: {e}")

        print("ğŸ¯ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")


def _init_default_data():
    """åˆå§‹åŒ–é»˜è®¤æ•°æ®"""
    print("ğŸ”§ æ£€æŸ¥å¹¶åˆå§‹åŒ–é»˜è®¤æ•°æ®...")

    # åˆå§‹åŒ–Configè¡¨çš„é»˜è®¤é…ç½®
    try:
        _ensure_default_configs()
        print("âœ… é»˜è®¤é…ç½®æ£€æŸ¥å®Œæˆ")
    except Exception as e:
        print(f"âŒ é…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")

    # åˆå§‹åŒ–LLMé…ç½®
    try:
        _ensure_default_llm_config()
        print("âœ… LLMé…ç½®æ£€æŸ¥å®Œæˆ")
    except Exception as e:
        print(f"âŒ LLMé…ç½®åˆå§‹åŒ–å¤±è´¥: {e}")

    # åˆå§‹åŒ–Promptsè¡¨çš„é»˜è®¤æ•°æ®
    try:
        _ensure_default_prompts()
        print("âœ… é»˜è®¤Promptæ£€æŸ¥å®Œæˆ")
    except Exception as e:
        print(f"âŒ Promptåˆå§‹åŒ–å¤±è´¥: {e}")


def _ensure_default_configs():
    """ç¡®ä¿é»˜è®¤é…ç½®å­˜åœ¨"""
    from config import Config as AppConfig

    default_configs = [
        ('thread_count', AppConfig.DEFAULT_THREAD_COUNT, 'int', 'é»˜è®¤çº¿ç¨‹æ•°'),
        ('max_concurrent_tasks', AppConfig.DEFAULT_MAX_CONCURRENT_TASKS, 'int', 'æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°'),
        ('download_timeout', AppConfig.DOWNLOAD_TIMEOUT, 'int', 'ä¸‹è½½è¶…æ—¶æ—¶é—´(ç§’)'),
        ('max_retry_count', AppConfig.MAX_RETRY_COUNT, 'int', 'æœ€å¤§é‡è¯•æ¬¡æ•°'),
        ('ffmpeg_threads', AppConfig.FFMPEG_THREADS, 'int', 'FFmpegè½¬æ¢çº¿ç¨‹æ•°'),
        ('auto_cleanup_days', AppConfig.AUTO_CLEANUP_DAYS, 'int', 'è‡ªåŠ¨æ¸…ç†å¤©æ•°'),
        ('enable_ai_naming', False, 'bool', 'å¯ç”¨AIæ™ºèƒ½å‘½ååŠŸèƒ½'),
    ]

    for key, value, value_type, description in default_configs:
        existing = Config.query.filter_by(key=key).first()
        if not existing:
            config_item = Config(key=key, value=value, value_type=value_type, description=description)
            db.session.add(config_item)

    db.session.commit()


def _ensure_default_llm_config():
    """ç¡®ä¿é»˜è®¤LLMé…ç½®å­˜åœ¨"""
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨LLMé…ç½®
    existing_config = Config.query.filter_by(key='llm_api_url').first()
    if existing_config:
        return  # å·²å­˜åœ¨é…ç½®ï¼Œä¸è¦†ç›–

    # è®¾ç½®é»˜è®¤LLMé…ç½®
    llm_configs = [
        ('llm_api_url', 'https://globalai.vip/v1/chat/completions', 'str', 'LLM APIæ¥å£åœ°å€'),
        ('llm_api_key', 'sk-rEh0PI8OkwAyOQbRX9xO7AwdrPPvhuin7x2FN7F96EAfI7ai', 'str', 'LLM APIå¯†é’¥'),
        ('llm_default_model', 'gpt-4.1', 'str', 'LLMé»˜è®¤æ¨¡å‹'),
        ('llm_default_max_tokens', 4096, 'int', 'LLMé»˜è®¤æœ€å¤§tokenæ•°'),
        ('llm_timeout', 30, 'int', 'LLMè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰'),
    ]

    for key, value, value_type, description in llm_configs:
        config_item = Config(key=key, value=value, value_type=value_type, description=description)
        db.session.add(config_item)

    db.session.commit()


def _ensure_default_prompts():
    """ç¡®ä¿é»˜è®¤Promptå­˜åœ¨"""
    # æ£€æŸ¥movie_name_extractor promptæ˜¯å¦å­˜åœ¨
    existing = Prompts.query.filter_by(key='movie_name_extractor').first()
    if existing:
        return  # å·²å­˜åœ¨ï¼Œä¸è¦†ç›–

    # åˆ›å»ºé»˜è®¤çš„movie_name_extractor prompt
    prompt_value = """ä½ æ˜¯ä¸€ä¸ªç”µå½±åå­—çš„å½’çº³å‘˜ã€‚æˆ‘æ­£åœ¨ä»ç½‘ç»œä¸Šä¸‹è½½ç”µå½±ï¼Œä½†æ˜¯ç”µå½±åå­—å¯ä»¥å¤¹å¸¦äº†ä¸€äº›ç½‘é¡µçš„ä¿¡æ¯ï¼Œè¯·ä½ ä»ä¸­æŠ½å–å»ç”µå½±çœŸæ­£çš„åå­—ã€‚

ä¾‹å¦‚ï¼š

è¾“å…¥ï¼šã€Šå°–å«ä¹‹åœ°ã€‹å…¨é›†åœ¨çº¿è§‚çœ‹ - ç”µå½± - åŠªåŠªå½±é™¢

ç”µå½±åï¼šå°–å«ä¹‹åœ°

æ³¨æ„ï¼š

1. ç”µå½±åå¯èƒ½å«æœ‰ç¼–å·ï¼Œä»¥åŠæ¼”å‘˜åå­—ï¼Œè¿™ä¹Ÿéœ€è¦ä¿ç•™

2. è¯·ä½ ç›´æ¥åªè¾“å‡ºç”µå½±ï¼Œä¸è¦è¾“å‡ºå…¶ä»–ä»»ä½•ä¿¡æ¯

è¾“å…¥ï¼š

{input}

ç”µå½±åï¼š"""

    prompt = Prompts(
        key='movie_name_extractor',
        value=prompt_value,
        description='æ ¹æ®è¾“å…¥çš„æ··æ‚ä¿¡æ¯ï¼ŒæŠ½å–å¹¶åªè¾“å‡ºç”µå½±çš„çœŸå®åç§°ï¼Œä¿ç•™ç¼–å·åŠæ¼”å‘˜åã€‚'
    )
    db.session.add(prompt)
    db.session.commit()

def restore_active_tasks():
    """æ¢å¤åº”ç”¨é‡å¯å‰çš„æ´»è·ƒä»»åŠ¡"""
    try:
        # è·å–æ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
        active_records = DownloadRecord.get_all_active()

        for record in active_records:
            if record.status == "downloading":
                # å°†ä¸‹è½½ä¸­çš„ä»»åŠ¡æ ‡è®°ä¸ºæš‚åœï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ¢å¤
                record.mark_paused()
            elif record.status == "queued":
                # å°†æ’é˜Ÿçš„ä»»åŠ¡é‡æ–°åŠ å…¥é˜Ÿåˆ—
                task_queue.append(record.task_id)

        db.session.commit()

        if active_records:
            print(f"æ¢å¤äº† {len(active_records)} ä¸ªæœªå®Œæˆçš„ä»»åŠ¡")

        # å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        process_task_queue()

    except Exception as e:
        print(f"æ¢å¤æ´»è·ƒä»»åŠ¡å¤±è´¥: {e}")

# æ·»åŠ ç»Ÿè®¡API
@app.route('/api/statistics', methods=['GET'])
def get_statistics():
    """è·å–ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯"""
    try:
        if not check_database_ready():
            # æ•°æ®åº“è¡¨è¿˜æœªåˆ›å»ºï¼Œè¿”å›é»˜è®¤ç»Ÿè®¡
            return jsonify({
                'total_tasks': 0,
                'completed_tasks': 0,
                'failed_tasks': 0,
                'active_tasks': 0,
                'success_rate': 0,
                'today_stats': {
                    'date': datetime.utcnow().date().isoformat(),
                    'total_downloads': 0,
                    'completed_downloads': 0,
                    'failed_downloads': 0,
                    'total_size': 0
                },
                'recent_stats': [],
                'database_initializing': True
            })

        # æ›´æ–°ä»Šæ—¥ç»Ÿè®¡
        DownloadStatistics.update_daily_stats()

        # è·å–åŸºæœ¬ç»Ÿè®¡
        total_tasks = DownloadRecord.query.count()
        completed_tasks = DownloadRecord.query.filter_by(status='completed').count()
        failed_tasks = DownloadRecord.query.filter_by(status='failed').count()
        active_tasks_count = DownloadRecord.query.filter(
            DownloadRecord.status.in_(['pending', 'downloading', 'paused', 'queued'])
        ).count()

        # è·å–ä»Šæ—¥ç»Ÿè®¡
        today_stats = DownloadStatistics.get_or_create_today()

        # è·å–æœ€è¿‘7å¤©çš„ç»Ÿè®¡
        from datetime import timedelta
        seven_days_ago = datetime.utcnow().date() - timedelta(days=7)
        recent_stats = DownloadStatistics.query.filter(
            DownloadStatistics.date >= seven_days_ago
        ).order_by(DownloadStatistics.date.desc()).all()

        return jsonify({
            'total_tasks': total_tasks,
            'completed_tasks': completed_tasks,
            'failed_tasks': failed_tasks,
            'active_tasks': active_tasks_count,
            'success_rate': round((completed_tasks / total_tasks * 100), 2) if total_tasks > 0 else 0,
            'today_stats': today_stats.to_dict(),
            'recent_stats': [stat.to_dict() for stat in recent_stats],
            'database_initializing': False
        })
    except Exception as e:
        return jsonify({'error': f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}'}), 500

@app.route('/api/tasks/cleanup', methods=['POST'])
def cleanup_old_tasks():
    """æ¸…ç†æ—§çš„å·²å®Œæˆä»»åŠ¡"""
    try:
        data = request.json or {}
        days = data.get('days', runtime_settings['auto_cleanup_days'])

        if days < 1 or days > 30:
            return jsonify({'error': 'æ¸…ç†å¤©æ•°å¿…é¡»åœ¨1-30ä¹‹é—´'}), 400

        cleaned_count = DownloadRecord.cleanup_old_records(days)
        return jsonify({
            'message': f'å·²æ¸…ç† {cleaned_count} ä¸ªæ—§ä»»åŠ¡è®°å½•',
            'cleaned_count': cleaned_count
        })
    except Exception as e:
        return jsonify({'error': f'æ¸…ç†ä»»åŠ¡å¤±è´¥: {str(e)}'}), 500


# ==================== Promptç®¡ç†API ====================

@app.route('/api/prompts', methods=['GET'])
def get_prompts():
    """è·å–æ‰€æœ‰prompts"""
    try:
        prompts = Prompts.query.all()
        return jsonify({
            'success': True,
            'prompts': [prompt.to_dict() for prompt in prompts]
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–promptså¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/prompts/<prompt_key>', methods=['GET'])
def get_prompt(prompt_key):
    """è·å–å•ä¸ªprompt"""
    try:
        prompt = Prompts.query.filter_by(key=prompt_key).first()
        if not prompt:
            return jsonify({
                'success': False,
                'error': 'Promptä¸å­˜åœ¨'
            }), 404

        return jsonify({
            'success': True,
            'prompt': prompt.to_dict()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–promptå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/prompts', methods=['POST'])
def create_prompt():
    """åˆ›å»ºæ–°çš„prompt"""
    try:
        data = request.get_json()

        if not data or 'key' not in data or 'value' not in data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘å¿…è¦å‚æ•°: key, value'
            }), 400

        key = data['key']
        value = data['value']
        description = data.get('description', '')

        # æ£€æŸ¥keyæ˜¯å¦å·²å­˜åœ¨
        existing = Prompts.query.filter_by(key=key).first()
        if existing:
            return jsonify({
                'success': False,
                'error': f'Prompt key "{key}" å·²å­˜åœ¨'
            }), 400

        # åˆ›å»ºæ–°prompt
        prompt = Prompts.set_prompt(key=key, value=value, description=description)

        return jsonify({
            'success': True,
            'message': 'Promptåˆ›å»ºæˆåŠŸ',
            'prompt': prompt.to_dict()
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'åˆ›å»ºpromptå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/prompts/<prompt_key>', methods=['PUT'])
def update_prompt(prompt_key):
    """æ›´æ–°prompt"""
    try:
        data = request.get_json()

        if not data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘æ›´æ–°æ•°æ®'
            }), 400

        prompt = Prompts.query.filter_by(key=prompt_key).first()
        if not prompt:
            return jsonify({
                'success': False,
                'error': 'Promptä¸å­˜åœ¨'
            }), 404

        # æ›´æ–°å­—æ®µ
        if 'value' in data:
            prompt.value = data['value']
        if 'description' in data:
            prompt.description = data['description']

        prompt.updated_at = datetime.utcnow()
        db.session.commit()

        return jsonify({
            'success': True,
            'message': 'Promptæ›´æ–°æˆåŠŸ',
            'prompt': prompt.to_dict()
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æ›´æ–°promptå¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/prompts/<prompt_key>', methods=['DELETE'])
def delete_prompt(prompt_key):
    """åˆ é™¤prompt"""
    try:
        prompt = Prompts.query.filter_by(key=prompt_key).first()
        if not prompt:
            return jsonify({
                'success': False,
                'error': 'Promptä¸å­˜åœ¨'
            }), 404

        db.session.delete(prompt)
        db.session.commit()

        return jsonify({
            'success': True,
            'message': 'Promptåˆ é™¤æˆåŠŸ'
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'åˆ é™¤promptå¤±è´¥: {str(e)}'
        }), 500


# ==================== LLMé…ç½®ç®¡ç†API ====================

@app.route('/api/llm/config', methods=['GET'])
def get_llm_config():
    """è·å–LLMé…ç½®"""
    try:
        config = LLMConfig.get_llm_config()
        # éšè—APIå¯†é’¥çš„æ•æ„Ÿä¿¡æ¯
        if config['api_key']:
            config['api_key'] = config['api_key'][:8] + '***' + config['api_key'][-4:]

        return jsonify({
            'success': True,
            'config': config
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'è·å–LLMé…ç½®å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/llm/config', methods=['POST'])
def update_llm_config():
    """æ›´æ–°LLMé…ç½®"""
    try:
        data = request.get_json()

        if not data:
            return jsonify({
                'success': False,
                'error': 'ç¼ºå°‘é…ç½®æ•°æ®'
            }), 400

        # æ›´æ–°é…ç½®
        LLMConfig.set_llm_config(
            api_url=data.get('api_url'),
            api_key=data.get('api_key'),
            default_model=data.get('default_model'),
            default_max_tokens=data.get('default_max_tokens'),
            timeout=data.get('timeout')
        )

        return jsonify({
            'success': True,
            'message': 'LLMé…ç½®æ›´æ–°æˆåŠŸ'
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'æ›´æ–°LLMé…ç½®å¤±è´¥: {str(e)}'
        }), 500


@app.route('/api/llm/test', methods=['POST'])
def test_llm_connection():
    """æµ‹è¯•LLMè¿æ¥"""
    try:
        # è¿™é‡Œå¯ä»¥æ·»åŠ LLMè¿æ¥æµ‹è¯•é€»è¾‘
        # æš‚æ—¶è¿”å›æˆåŠŸçŠ¶æ€
        return jsonify({
            'success': True,
            'message': 'LLMè¿æ¥æµ‹è¯•æˆåŠŸ'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'LLMè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/database/init', methods=['POST'])
def manual_init_database():
    """æ‰‹åŠ¨åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        print("æ”¶åˆ°æ‰‹åŠ¨åˆå§‹åŒ–æ•°æ®åº“è¯·æ±‚")
        init_database()

        if check_database_ready():
            return jsonify({
                'success': True,
                'message': 'æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—'
            }), 500

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}'
        }), 500

@app.route('/api/database/status', methods=['GET'])
def get_database_status():
    """è·å–æ•°æ®åº“çŠ¶æ€"""
    try:
        db_path = app.config['SQLALCHEMY_DATABASE_URI'].replace('sqlite:///', '')

        status = {
            'database_file_exists': os.path.exists(db_path),
            'database_file_size': os.path.getsize(db_path) if os.path.exists(db_path) else 0,
            'database_ready': check_database_ready(),
            'database_path': db_path
        }

        if status['database_ready']:
            with app.app_context():
                from sqlalchemy import inspect
                inspector = inspect(db.engine)
                status['tables'] = inspector.get_table_names()
        else:
            status['tables'] = []

        return jsonify(status)

    except Exception as e:
        return jsonify({
            'error': f'è·å–æ•°æ®åº“çŠ¶æ€å¤±è´¥: {str(e)}'
        }), 500


if __name__ == '__main__':
    print("Flask M3U8 ä¸‹è½½ç®¡ç†å™¨å¯åŠ¨ä¸­...")
    print(f"ä¸‹è½½ç›®å½•: {DOWNLOAD_DIR}")

    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()

    print("è®¿é—®åœ°å€: http://localhost:5001")
    app.run(debug=True, host='0.0.0.0', port=5001)
